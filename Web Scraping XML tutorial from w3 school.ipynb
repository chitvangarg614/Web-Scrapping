{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import xlsxwriter\n",
    "from openpyxl import Workbook\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook(\"workbook.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "rowHeaders = ['Heading','Content','Table Data','Links','Code']\n",
    "worksheet.write_row(row, col, tuple(rowHeaders))\n",
    "row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL =[\"https://www.w3schools.in/xml/#\",\"https://www.w3schools.in/xml/intro/\",\"https://www.w3schools.in/xml/declaration/\",\"https://www.w3schools.in/xml/syntax/\", \"https://www.w3schools.in/xml/comments/\"]\n",
    "for url in range(0,4):\n",
    "    req = requests.get(URL[url])\n",
    "    sleep(randint(5,10))\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    titles = soup.find_all('title')\n",
    "    content = soup.find_all('p')\n",
    "    table= [(item.prettify()) for item in soup.find_all(\"table\")]\n",
    "    links=[]\n",
    "    for link in soup.find_all('a'):\n",
    "        links.append(link.get('href'))\n",
    "    code = soup.find_all('pre')        \n",
    "    titles= str(titles)\n",
    "    content=str(content)\n",
    "    table= str(table)\n",
    "    links= str(links)\n",
    "    code=str(code)\n",
    "    rowValues = [titles, content, table, links,code ]\n",
    "    worksheet.write_row(row, col, tuple(rowValues))\n",
    "    row=row+1\n",
    "workbook.close()\n",
    "sleep(5)\n",
    "\n",
    "#url='https://www.w3schools.in/xml/declaration/'\n",
    "#req= requests.get(url)\n",
    "#soup = BeautifulSoup(req.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
